{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c59ce587-ba2f-4b94-8199-2dd97a2b0fb4",
        "id": "ShgvmapvX8b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = \"/content/drive/MyDrive/DIP_OEL/PH2Dataset\""
      ],
      "metadata": {
        "id": "e6gfZVSWX8b7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(BASE_PATH)[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa505b72-6655-4de1-c0ef-c4ddf92b2480",
        "id": "DVE3De5JX8b8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Readme.txt', 'PH2_dataset.txt', 'PH2_dataset.xlsx', 'PH2 Dataset images']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROJECT START\n",
        "\n",
        "Task 1 â€” Lesion Segmentation & Mask Generation\n",
        "\n",
        "ðŸ”¹ Required Libraries"
      ],
      "metadata": {
        "id": "SM4lLQIGX8b9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "jimjAhu7X8b-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”¹ Helper Functions (Image Processing Pipeline) 1ï¸âƒ£ Image Enhancement"
      ],
      "metadata": {
        "id": "2UqZHk14X8b-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def enhance_image(img):\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    l = clahe.apply(l)\n",
        "    enhanced = cv2.merge((l, a, b))\n",
        "    return cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)"
      ],
      "metadata": {
        "id": "M2ruUivpX8cA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2ï¸âƒ£ Hair Removal (Black-hat + Inpainting)"
      ],
      "metadata": {
        "id": "FoT5FtBFX8cB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_hairs(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (17,17))\n",
        "    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n",
        "    _, mask = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)\n",
        "    return cv2.inpaint(img, mask, 1, cv2.INPAINT_TELEA)"
      ],
      "metadata": {
        "id": "49Enzep1X8cC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3ï¸âƒ£ Lesion Segmentation"
      ],
      "metadata": {
        "id": "-pdH9xXpX8cC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_lesion(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
        "\n",
        "    _, binary = cv2.threshold(\n",
        "    blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n",
        ")\n",
        "\n",
        "\n",
        "    # 1ï¸âƒ£ CLOSE â€” lesion boundaries connect karne ke liye\n",
        "    kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7,7))\n",
        "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel_close)\n",
        "\n",
        "    # 2ï¸âƒ£ FILL HOLES â€” gaps remove karne ke liye\n",
        "    h, w = binary.shape\n",
        "    floodfill = binary.copy()\n",
        "    mask = np.zeros((h+2, w+2), np.uint8)\n",
        "    cv2.floodFill(floodfill, mask, (0,0), 255)\n",
        "    floodfill_inv = cv2.bitwise_not(floodfill)\n",
        "    filled = binary | floodfill_inv\n",
        "\n",
        "    return filled"
      ],
      "metadata": {
        "id": "r-VLQZ0UX8cD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”¹ Main Mask Generation Loop"
      ],
      "metadata": {
        "id": "Tea40YFUX8cE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = \"/content/drive/MyDrive/DIP_OEL/PH2Dataset/PH2 Dataset images\"\n",
        "SAVE_PATH = \"/content/drive/MyDrive/DIP_OEL/PH2Dataset/generated_masks\"\n",
        "\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "\n",
        "y_true_all, y_pred_all = [], []\n",
        "\n",
        "for folder in tqdm(os.listdir(BASE_PATH)):\n",
        "    folder_path = os.path.join(BASE_PATH, folder)\n",
        "\n",
        "    if not os.path.isdir(folder_path):\n",
        "        continue\n",
        "\n",
        "    img_path = os.path.join(\n",
        "        folder_path, f\"{folder}_Dermoscopic_Image\"\n",
        "    )\n",
        "    gt_path = os.path.join(\n",
        "        folder_path, f\"{folder}_lesion\"\n",
        "    )\n",
        "\n",
        "    img_file = os.listdir(img_path)[0]\n",
        "    gt_file  = os.listdir(gt_path)[0]\n",
        "\n",
        "    img = cv2.imread(os.path.join(img_path, img_file))\n",
        "    gt  = cv2.imread(os.path.join(gt_path, gt_file), 0)\n",
        "\n",
        "    if img is None or gt is None:\n",
        "        continue\n",
        "\n",
        "    img = enhance_image(img)\n",
        "    img = remove_hairs(img)\n",
        "    pred_mask = segment_lesion(img)\n",
        "\n",
        "    cv2.imwrite(\n",
        "        os.path.join(SAVE_PATH, f\"{folder}_mask.png\"),\n",
        "        pred_mask\n",
        "    )\n",
        "\n",
        "    y_true_all.extend((gt > 0).flatten())\n",
        "    y_pred_all.extend((pred_mask > 0).flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d4d5cf5-14e3-4f8c-e7c0-addc5c0be970",
        "id": "V6_PNN0sX8cE"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [05:54<00:00,  1.77s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7acfb2f1",
        "outputId": "da9ecb1f-997a-4482-94e8-7b22dafd030c"
      },
      "source": [
        "import os\n",
        "\n",
        "path_to_verify = '/content/drive/MyDrive/DIP_OEL/PH2Dataset/PH2 Dataset images'\n",
        "\n",
        "if os.path.exists(path_to_verify):\n",
        "    if os.path.isdir(path_to_verify):\n",
        "        print(f\"Path '{path_to_verify}' exists and is a directory.\")\n",
        "        print(\"Contents (first 10 items):\", os.listdir(path_to_verify)[:5])\n",
        "    else:\n",
        "        print(f\"Path '{path_to_verify}' exists but is not a directory.\")\n",
        "else:\n",
        "    print(f\"Path '{path_to_verify}' does not exist.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path '/content/drive/MyDrive/DIP_OEL/PH2Dataset/PH2 Dataset images' exists and is a directory.\n",
            "Contents (first 10 items): ['IMD004', 'IMD009', 'IMD002', 'IMD003', 'IMD008']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“Š 3. Segmentation Evaluation (Dataset-Level)"
      ],
      "metadata": {
        "id": "03uObx-xX8cF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_true_all, y_pred_all)\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "sensitivity = TP / (TP + FN)\n",
        "specificity = TN / (TN + FP)\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(f\"Accuracy     : {accuracy:.4f}\")\n",
        "print(f\"Sensitivity  : {sensitivity:.4f}\")\n",
        "print(f\"Specificity  : {specificity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24131227-f8ea-482f-9cf6-16853e074cb5",
        "id": "4wQNHu2uX8cF"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[ 2133754 57593928]\n",
            " [  933741 27501900]]\n",
            "Accuracy     : 0.3361\n",
            "Sensitivity  : 0.9672\n",
            "Specificity  : 0.0357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Import libraries and mount drive"
      ],
      "metadata": {
        "id": "eJhApqOBX_LQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/DIP_OEL/PH2Dataset/PH2 Dataset images\"\n",
        "SAVE_PATH = \"/content/drive/MyDrive/DIP_OEL/PH2Dataset/Masks\"  # jahan masks saved hain\n",
        "LABEL_TXT = \"/content/drive/MyDrive/DIP_OELT/PH2Dataset/PH2_dataset.txt\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVqoBHlfYBSH",
        "outputId": "e850e38f-f823-4044-bb9e-a8d7f72068e2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load labels from .txt file"
      ],
      "metadata": {
        "id": "z0zMgsixYE0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL_TXT = \"/content/drive/MyDrive/DIP_OEL/PH2Dataset/PH2_dataset.txt\"\n",
        "label_dict = {}\n",
        "\n",
        "with open(LABEL_TXT, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "for line in lines:\n",
        "    if line.strip() == \"\":\n",
        "        continue\n",
        "\n",
        "    parts = line.strip().split(\"||\")\n",
        "    parts = [p.strip() for p in parts if p.strip() != \"\"]\n",
        "\n",
        "    # Skip header\n",
        "    if parts[0] == \"Name\":\n",
        "        continue\n",
        "\n",
        "    img_id = parts[0]\n",
        "\n",
        "    try:\n",
        "        melanoma_val = parts[-1].split()[0]\n",
        "        melanoma_val = int(melanoma_val)\n",
        "        label = 1 if melanoma_val > 0 else 0\n",
        "        label_dict[img_id] = label\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(\"Total labels loaded:\", len(label_dict))\n",
        "print(\"Sample:\", list(label_dict.items())[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icGyUArRYHB3",
        "outputId": "6baac1ed-30f7-48bf-db4c-8388f320b946"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total labels loaded: 212\n",
            "Sample: [('IMD003', 1), ('IMD009', 1), ('IMD016', 1), ('IMD022', 1), ('IMD024', 1), ('IMD025', 1), ('IMD035', 1), ('IMD038', 1), ('IMD042', 1), ('IMD044', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Define feature extraction function"
      ],
      "metadata": {
        "id": "1_hGQL_eYRvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(img, mask):\n",
        "    features = []\n",
        "\n",
        "    # strict binary mask\n",
        "    mask = (mask > 0).astype(np.uint8)\n",
        "\n",
        "    for i in range(3):  # BGR channels\n",
        "        channel = img[:, :, i]\n",
        "        lesion_pixels = channel[mask == 1]\n",
        "\n",
        "        if lesion_pixels.size < 50:   # too small region\n",
        "            features.extend([0, 0])\n",
        "        else:\n",
        "            features.extend([\n",
        "                np.mean(lesion_pixels) / 255.0,\n",
        "                np.std(lesion_pixels) / 255.0\n",
        "            ])\n",
        "    return features\n",
        "\n"
      ],
      "metadata": {
        "id": "lcgm4j6eYUL1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load images, masks, extract features"
      ],
      "metadata": {
        "id": "Xe7WxQ7nYW_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ----------------------\n",
        "# Step 0: Mount Drive\n",
        "# ----------------------\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ----------------------\n",
        "# Step 1: Define Paths\n",
        "# ----------------------\n",
        "BASE_PATH = \"/content/drive/MyDrive/DIP_OEL/PH2Dataset/PH2 Dataset images\"\n",
        "SAVE_PATH = \"/content/drive/MyDrive/DIP_OEL/PH2Dataset/generated_masks\"\n",
        "LABEL_TXT = \"/content/drive/MyDrive/DIP_OEL/PH2Dataset/PH2_dataset.txt\"\n",
        "\n",
        "# ----------------------\n",
        "# Step 2: Load Labels from .txt\n",
        "# ----------------------\n",
        "label_dict = {}\n",
        "\n",
        "with open(LABEL_TXT, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "for line in lines:\n",
        "    if line.strip() == \"\":\n",
        "        continue\n",
        "\n",
        "    parts = line.strip().split(\"||\")\n",
        "    parts = [p.strip() for p in parts if p.strip() != \"\"]\n",
        "\n",
        "    # Skip header\n",
        "    if parts[0] == \"Name\":\n",
        "        continue\n",
        "\n",
        "    img_id = parts[0]\n",
        "\n",
        "    try:\n",
        "        melanoma_val = parts[-1].split()[0]\n",
        "        melanoma_val = int(melanoma_val)\n",
        "        label = 1 if melanoma_val > 0 else 0\n",
        "        label_dict[img_id] = label\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(\"Total labels loaded:\", len(label_dict))\n",
        "print(\"Sample labels:\", list(label_dict.items())[:10])\n",
        "\n",
        "# ----------------------\n",
        "# Step 3: Define Feature Extraction\n",
        "# ----------------------\n",
        "def extract_features(img, mask):\n",
        "    \"\"\"\n",
        "    Extract simple features from masked image:\n",
        "    mean and std for each channel (BGR)\n",
        "    \"\"\"\n",
        "    features = []\n",
        "\n",
        "    # Ensure mask is binary\n",
        "    _, mask_bin = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    for i in range(3):  # B, G, R channels\n",
        "        masked_pixels = img[:, :, i][mask_bin > 0]\n",
        "        if masked_pixels.size == 0:\n",
        "            features.extend([0, 0])\n",
        "        else:\n",
        "            features.extend([masked_pixels.mean(), masked_pixels.std()])\n",
        "    return features  # total 6 features\n",
        "\n",
        "# ----------------------\n",
        "# Step 4: Load Images, Masks and Extract Features\n",
        "# ----------------------\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "missing_masks = []\n",
        "missing_images = []\n",
        "\n",
        "for folder in os.listdir(BASE_PATH):\n",
        "    folder_path = os.path.join(BASE_PATH, folder)\n",
        "\n",
        "    if folder not in label_dict:\n",
        "        continue\n",
        "\n",
        "    # Mask path\n",
        "    mask_path = os.path.join(SAVE_PATH, f\"{folder}_mask.png\")\n",
        "    if not os.path.exists(mask_path):\n",
        "        missing_masks.append(folder)\n",
        "        continue\n",
        "\n",
        "    # Image path\n",
        "    img_folder = os.path.join(folder_path, f\"{folder}_Dermoscopic_Image\")\n",
        "    if not os.path.exists(img_folder):\n",
        "        missing_images.append(folder)\n",
        "        continue\n",
        "\n",
        "    img_files = os.listdir(img_folder)\n",
        "    if len(img_files) == 0:\n",
        "        missing_images.append(folder)\n",
        "        continue\n",
        "\n",
        "    img_file = img_files[0]\n",
        "    img = cv2.imread(os.path.join(img_folder, img_file))\n",
        "    mask = cv2.imread(mask_path, 0)  # grayscale\n",
        "\n",
        "    if img is None or mask is None:\n",
        "        missing_images.append(folder)\n",
        "        continue\n",
        "\n",
        "    feats = extract_features(img, mask)\n",
        "    X.append(feats)\n",
        "    y.append(label_dict[folder])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Labels shape:\", y.shape)\n",
        "print(\"Missing masks:\", len(missing_masks))\n",
        "print(\"Missing images:\", len(missing_images))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM3_QiNhYYbp",
        "outputId": "a7d2d785-5d83-4f92-f370-b8a7e35f32f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Total labels loaded: 212\n",
            "Sample labels: [('IMD003', 1), ('IMD009', 1), ('IMD016', 1), ('IMD022', 1), ('IMD024', 1), ('IMD025', 1), ('IMD035', 1), ('IMD038', 1), ('IMD042', 1), ('IMD044', 1)]\n",
            "Features shape: (200, 6)\n",
            "Labels shape: (200,)\n",
            "Missing masks: 0\n",
            "Missing images: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train/Test Split Example"
      ],
      "metadata": {
        "id": "1hxFGsJ5a2oE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "Eu03wPL5a4tb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier:"
      ],
      "metadata": {
        "id": "I_X0fqlgbYyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Train Random Forest\n",
        "clf = RandomForestClassifier(\n",
        "    n_estimators=50,\n",
        "    max_depth=5,\n",
        "    min_samples_split=5,\n",
        "    random_state=42\n",
        ")\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAOt72zoa8yG",
        "outputId": "ac10c55a-a9cb-4a0b-9fb6-a7a590920ac3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        40\n",
            "\n",
            "    accuracy                           1.00        40\n",
            "   macro avg       1.00      1.00      1.00        40\n",
            "weighted avg       1.00      1.00      1.00        40\n",
            "\n"
          ]
        }
      ]
    }
  ]
}